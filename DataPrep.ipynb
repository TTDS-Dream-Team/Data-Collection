{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "charged-beginning",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import ijson\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "behind-sandwich",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = '/Users/calummcmeekin/Downloads'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "original-secretariat",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_lines(filename):\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        for i, l in enumerate(f):\n",
    "            pass\n",
    "    return i\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspended-appliance",
   "metadata": {},
   "source": [
    "goodreads_books.json.gz has 2360654 lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "australian-pursuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_isbn_data(file_name, head=1000):\n",
    "    count = 0\n",
    "    \n",
    "    bookID_to_ISBN = {}\n",
    "\n",
    "    with gzip.open(file_name) as fin:\n",
    "        for l in fin:\n",
    "            d = json.loads(l)\n",
    "            count += 1\n",
    "\n",
    "            bookID_to_ISBN[d['book_id']] = d['isbn']\n",
    "                \n",
    "            if ((count % 100000) == 0):\n",
    "                print (\"Currently exported: {}\".format(count))\n",
    "                \n",
    "    return bookID_to_ISBN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "indirect-scheduling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_review_data(file_name):\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    reviews_df = pd.DataFrame()\n",
    "    \n",
    "    review_to_bookID = {}\n",
    "    \n",
    "    with gzip.open(file_name) as fin:\n",
    "        for l in fin:\n",
    "            \n",
    "            \n",
    "            if (count < 15739966/3):\n",
    "                \n",
    "                d = json.loads(l)\n",
    "              \n",
    "                #append row to the dataframe\n",
    "                #reviews_df = reviews_df.append(review_to_bookID, ignore_index=True)\n",
    "\n",
    "                review_to_bookID[d['review_text']] = d['book_id']\n",
    "\n",
    "                if ((count % 100000) == 0):\n",
    "                    print (\"Currently exported: {:.2f}%\".format(count/(15739966/3)*100))\n",
    "\n",
    "            else:\n",
    "                break\n",
    "\n",
    "            count += 1\n",
    "\n",
    "                \n",
    "    return review_to_bookID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spectacular-accused",
   "metadata": {},
   "source": [
    "**Export ISBN to book IDs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "referenced-lecture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________EXPORTING BOOKS______________\n",
      "Currently exported: 100000\n",
      "Currently exported: 200000\n",
      "Currently exported: 300000\n",
      "Currently exported: 400000\n",
      "Currently exported: 500000\n",
      "Currently exported: 600000\n",
      "Currently exported: 700000\n",
      "Currently exported: 800000\n",
      "Currently exported: 900000\n",
      "Currently exported: 1000000\n",
      "Currently exported: 1100000\n",
      "Currently exported: 1200000\n",
      "Currently exported: 1300000\n",
      "Currently exported: 1400000\n",
      "Currently exported: 1500000\n",
      "Currently exported: 1600000\n",
      "Currently exported: 1700000\n",
      "Currently exported: 1800000\n",
      "Currently exported: 1900000\n",
      "Currently exported: 2000000\n",
      "Currently exported: 2100000\n",
      "Currently exported: 2200000\n",
      "Currently exported: 2300000\n",
      "\n",
      "TIME: 163.202305\n"
     ]
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "\n",
    "print (\"_____________EXPORTING BOOKS______________\")\n",
    "bookID_to_ISBN = load_isbn_data(os.path.join(DIR, 'goodreads_books.json.gz'), )\n",
    "\n",
    "print(\"\\nTIME: {}\".format(time.process_time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aquatic-wilderness",
   "metadata": {},
   "source": [
    "**Get number of lines in each file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "starting-print",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2360654 books\n",
      "There are 15739966 book reviews\n"
     ]
    }
   ],
   "source": [
    "num_books = count_lines(os.path.join(DIR, 'goodreads_books.json.gz'))\n",
    "num_reviews = count_lines(os.path.join(DIR, 'goodreads_reviews_dedup.json.gz'))\n",
    "\n",
    "print(\"There are {} books\".format(num_books))\n",
    "print(\"There are {} book reviews\".format(num_reviews))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-freeze",
   "metadata": {},
   "source": [
    "**Export reviews**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "statistical-hundred",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________EXPORTING REVIEWS______________\n",
      "Currently exported: 0.00%\n",
      "Currently exported: 1.91%\n",
      "Currently exported: 3.81%\n",
      "Currently exported: 5.72%\n",
      "Currently exported: 7.62%\n",
      "Currently exported: 9.53%\n",
      "Currently exported: 11.44%\n",
      "Currently exported: 13.34%\n",
      "Currently exported: 15.25%\n",
      "Currently exported: 17.15%\n",
      "Currently exported: 19.06%\n",
      "Currently exported: 20.97%\n",
      "Currently exported: 22.87%\n",
      "Currently exported: 24.78%\n",
      "Currently exported: 26.68%\n",
      "Currently exported: 28.59%\n",
      "Currently exported: 30.50%\n",
      "Currently exported: 32.40%\n",
      "Currently exported: 34.31%\n",
      "Currently exported: 36.21%\n",
      "Currently exported: 38.12%\n",
      "Currently exported: 40.03%\n",
      "Currently exported: 41.93%\n",
      "Currently exported: 43.84%\n",
      "Currently exported: 45.74%\n",
      "Currently exported: 47.65%\n",
      "Currently exported: 49.56%\n",
      "Currently exported: 51.46%\n",
      "Currently exported: 53.37%\n",
      "Currently exported: 55.27%\n",
      "Currently exported: 57.18%\n",
      "Currently exported: 59.09%\n",
      "Currently exported: 60.99%\n",
      "Currently exported: 62.90%\n",
      "Currently exported: 64.80%\n",
      "Currently exported: 66.71%\n",
      "Currently exported: 68.62%\n",
      "Currently exported: 70.52%\n",
      "Currently exported: 72.43%\n",
      "Currently exported: 74.33%\n",
      "Currently exported: 76.24%\n",
      "Currently exported: 78.15%\n",
      "Currently exported: 80.05%\n",
      "Currently exported: 81.96%\n",
      "Currently exported: 83.86%\n",
      "Currently exported: 85.77%\n",
      "Currently exported: 87.67%\n",
      "Currently exported: 89.58%\n",
      "Currently exported: 91.49%\n",
      "Currently exported: 93.39%\n",
      "Currently exported: 95.30%\n",
      "Currently exported: 97.20%\n",
      "Currently exported: 99.11%\n",
      "\n",
      "TIME: 110.829442\n"
     ]
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "\n",
    "print (\"_____________EXPORTING REVIEWS______________\")\n",
    "reviews = load_review_data(os.path.join(DIR, 'goodreads_reviews_dedup.json.gz'))\n",
    "\n",
    "print(\"\\nTIME: {}\".format(time.process_time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dimensional-refund",
   "metadata": {},
   "source": [
    "Number of unique reviews: 2,080,190"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-newman",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df = pd.read_json(os.path.join(DIR, 'goodreads_reviews_dedup.json.gz'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incredible-athletics",
   "metadata": {},
   "source": [
    "**Convert JSON objects to Pandas DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "micro-humidity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ISBN dataframe\n",
    "isbn_df = pd.DataFrame()\n",
    "\n",
    "isbn_df['isbn'] = bookID_to_ISBN.keys()\n",
    "isbn_df['book_id'] = bookID_to_ISBN.values()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joint-alcohol",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Book_ID and reviews dataframe\n",
    "reviews_df = pd.DataFrame()\n",
    "\n",
    "reviews_df['review'] = reviews.keys()\n",
    "reviews_df['book_id'] = reviews.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "regular-satisfaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df_2 = pd.DataFrame(reviews_df.items(), columns=['review_text', 'book_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silent-fiction",
   "metadata": {},
   "source": [
    "**Pickle the dataframe for quick access**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-lingerie",
   "metadata": {},
   "outputs": [],
   "source": [
    "isbn_df.to_pickle(\"isbn_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "russian-authority",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-bfb796700825>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreviews_df_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"reviews_df.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/ttds/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_pickle\u001b[0;34m(self, path, compression, protocol)\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpickle\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2676\u001b[0;31m         \u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2678\u001b[0m     def to_clipboard(\n",
      "\u001b[0;32m~/miniconda3/envs/ttds/lib/python3.8/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mto_pickle\u001b[0;34m(obj, filepath_or_buffer, compression, protocol)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHIGHEST_PROTOCOL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "reviews_df_2.to_pickle(\"reviews_df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radical-conviction",
   "metadata": {},
   "source": [
    "**Read Pickled Dataframes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "lucky-recording",
   "metadata": {},
   "outputs": [],
   "source": [
    "isbn_df = pd.read_pickle(\"isbn_df.pkl\")\n",
    "\n",
    "reviews_df = pd.read_pickle(\"reviews_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "removable-matthew",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_df = reduce(lambda x,y: pd.merge(x,y, on='book_id', how='outer'), [isbn_df, reviews_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interim-diabetes",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "lined-leeds",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_df_2 = mixed_df[mixed_df['review_text'].isnull() == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "buried-malta",
   "metadata": {},
   "outputs": [],
   "source": [
    "del isbn_df\n",
    "del reviews_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "legendary-definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_df_2.to_pickle(\"clean_reviews_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "mighty-comfort",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5054025, 3)\n"
     ]
    }
   ],
   "source": [
    "print (mixed_df_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "meaning-drove",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reviews' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-f9e2bd43b646>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mindex_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mcur_review\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreviews\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mcur_review_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'reviews' is not defined"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "\n",
    "index_key = 0\n",
    "\n",
    "for cur_review in reviews:\n",
    "    \n",
    "    cur_review_json = {}\n",
    "    \n",
    "    cur_book_id = reviews[cur_review]\n",
    "    \n",
    "    cur_review_json['isbn'] = bookID_to_ISBN[cur_book_id]\n",
    "    cur_review_json['book_id'] = reviews[cur_review]\n",
    "    cur_review_json['review_text'] = cur_review\n",
    "    \n",
    "    data[index_key] = cur_review_json\n",
    "    \n",
    "    index_key += 1\n",
    "        \n",
    "    if (index_key % 100000 == 0):\n",
    "        print (\"Currently exported: {:.2f}%\".format(index_key/15107456*100))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "refined-stream",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('skeleton_review_data.json', 'w') as outfile:\n",
    "    json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "stylish-roller",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'isbn': '', 'book_id': '24375664', 'review_text': \"Mind blowingly cool. Best science fiction I've read in some time. I just loved all the descriptions of the society of the future - how they lived in trees, the notion of owning property or even getting married was gone. How every surface was a screen. \\n The undulations of how society responds to the Trisolaran threat seem surprising to me. Maybe its more the Chinese perspective, but I wouldn't have thought the ETO would exist in book 1, and I wouldn't have thought people would get so over-confident in our primitive fleet's chances given you have to think that with superior science they would have weapons - and defenses - that would just be as rifles to arrows once were. \\n But the moment when Luo Ji won as a wallfacer was just too cool. I may have actually done a fist pump. Though by the way, if the Dark Forest theory is right - and I see no reason why it wouldn't be - we as a society should probably stop broadcasting so much signal out into the universe.\"}, 1: {'isbn': '', 'book_id': '18245960', 'review_text': 'This is a special book. It started slow for about the first third, then in the middle third it started to get interesting, then the last third blew my mind. This is what I love about good science fiction - it pushes your thinking about where things can go. \\n It is a 2015 Hugo winner, and translated from its original Chinese, which made it interesting in just a different way from most things I\\'ve read. For instance the intermixing of Chinese revolutionary history - how they kept accusing people of being \"reactionaries\", etc. \\n It is a book about science, and aliens. The science described in the book is impressive - its a book grounded in physics and pretty accurate as far as I could tell. Though when it got to folding protons into 8 dimensions I think he was just making stuff up - interesting to think about though. \\n But what would happen if our SETI stations received a message - if we found someone was out there - and the person monitoring and answering the signal on our side was disillusioned? That part of the book was a bit dark - I would like to think human reaction to discovering alien civilization that is hostile would be more like Enders Game where we would band together. \\n I did like how the book unveiled the Trisolaran culture through the game. It was a smart way to build empathy with them and also understand what they\\'ve gone through across so many centuries. And who know a 3 body problem was an unsolvable math problem? But I still don\\'t get who made the game - maybe that will come in the next book. \\n I loved this quote: \\n \"In the long history of scientific progress, how many protons have been smashed apart in accelerators by physicists? How many neutrons and electrons? Probably no fewer than a hundred million. Every collision was probably the end of the civilizations and intelligences in a microcosmos. In fact, even in nature, the destruction of universes must be happening at every second--for example, through the decay of neutrons. Also, a high-energy cosmic ray entering the atmosphere may destroy thousands of such miniature universes....\"'}}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "naval-boulder",
   "metadata": {},
   "source": [
    "**Load data JSON to check contents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "rising-citizen",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"skeleton_review_data.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "guided-diamond",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "chunksize can only be passed if lines=True",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-550786eedd9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/ttds/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ttds/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m                 )\n\u001b[1;32m    295\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ttds/lib/python3.8/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines, chunksize, compression, nrows)\u001b[0m\n\u001b[1;32m    595\u001b[0m     )\n\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m     json_reader = JsonReader(\n\u001b[0m\u001b[1;32m    598\u001b[0m         \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0morient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morient\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ttds/lib/python3.8/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines, chunksize, compression, nrows)\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"chunksize\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"chunksize can only be passed if lines=True\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnrows\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: chunksize can only be passed if lines=True"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amber-mandate",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
